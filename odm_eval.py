import numpy as np
import matplotlib.pyplot as pyplot
import rasterio as rio
import pandas as pd
import os
from GCP import convert_coordinate_UTM
from writer import save_image, save_data
import json
import time



'''
TODO - use indexing to get 1x1 m box with additional statistics


'''

class MiniArea:
    def __init__(self, ODM_object,x, y, size=10):
        print(x,y)
        self.pixel_length_x, self.pixel_length_y = ODM_object.x_pixel_len, ODM_object.y_pixel_len
        rows, cols = int(size // self.pixel_length_y), int(size // self.pixel_length_x)
        print(f'{rows =}{cols=}')
        row_min, row_max, col_min, col_max = y-rows//2, y+rows//2,x-cols//2,x+cols//2
        print(row_min, row_max, col_min, col_max)
        matrix_mini_area = np.asarray(ODM_object.canopy_model)
        
        self.matrix_mini_area = matrix_mini_area[row_min:row_max, col_min:col_max]
        print(self.matrix_mini_area.shape)


class ODMEval:
    def __init__(self, project_location, save=False):
        self.project_location = project_location
        self.scrap_project_data()
        if save:
            self.save()
        #self.show_orthophoto()
        s = time.time()
        print('volume = ', self.find_volume())
        print(time.time()-s)

    # returns array of sizeXsize around the gps_x,gps_y point in orthophoto
    def mini_area(self,gps_x, gps_y, size=10):
        x,y = self.index_to_pixel(gps_x, gps_y) 
        return MiniArea(self, x,y)        


    def __sub__(self, other):
        # bounding box tuple is ordered in this way left, bottom, right, top
        '''
        larger right and upper means bigger
        smaller left and bottom means bigger
        '''
        name_other = other.project_location.split('/')[-1]
        name_self = self.project_location.split('/')[-1]
        print(f'subtracting {name_self} - {name_other}')

        min_dimensions = []
        for i, locations in enumerate(zip(self.bounds, other.bounds)):
            # first two are left and bottom which are smaller is bigger
            if i <2:
                min_dimensions.append(max(locations))
            # this is for right and upper where max is bigger 
            else:
                min_dimensions.append(min(locations))


        # min_dimensions should be where the two overlap


        # index upper left
        self_lower_row, self_lower_col = self.index_to_pixel(min_dimensions[0], min_dimensions[3])
        other_lower_row, other_lower_col = other.index_to_pixel(min_dimensions[0], min_dimensions[3])

        self_upper_row, self_upper_col = self.index_to_pixel(min_dimensions[2], min_dimensions[1])
        other_upper_row, other_upper_col = other.index_to_pixel(min_dimensions[2], min_dimensions[1])

         
        self_row, self_col = self_upper_row - self_lower_row,self_upper_col - self_lower_col
        other_row, other_col =other_upper_row - other_lower_row,other_upper_col - other_lower_col 
        
        # force shape to be the same, can be slightly offset by 1
        if self_row != other_row:
            diff = abs(self_row - other_row)
            if self_upper_row > other_upper_row:
                self_upper_row -= diff 
            else:
                other_upper_row -= diff

        if self_col != other_col:
            diff = abs(self_col - other_col)
            if self_upper_col > other_upper_col:
                self_upper_col -= diff
            else:
                other_upper_col -= diff

       
        # indexing to cutout correct shape 
        self_np = self.canopy_model[self_lower_row:self_upper_row, self_lower_col:self_upper_col]
        other_np = other.canopy_model[other_lower_row:other_upper_row, other_lower_col:other_upper_col]
        print(self_np.shape)
        print(self_np.shape)

        return self_np - other_np 



    # returns row, col pixels relating to specific coordinate x,y 
    def index_to_pixel(self, x,y):
        return rio.transform.rowcol(self.affine, x, y)

    # return coordinate relating to specific pixel xy, inverse of index func
    def index_to_coordinate(self, x,y):
        return self.affine * (x,y) 

    def save(self):
        # save the masked versions of dsm and dtm since normal tif version is not easily readable
        print('Saving Tiffs as jpgs for human readability')
        save_image(self.dsm, 'masked_dsm.jpg', self.project_location)
        save_image(self.dtm, 'masked_dtm.jpg', self.project_location)
        print('Saving canopy model')
        save_image(self.canopy_model, 'canopy.jpg', self.project_location)


    # get all data from project:
    def scrap_project_data(self):
        print('Getting data generated by the ODM')
        dsm_path = self.project_location + '/odm_dem/dsm.tif'
        dtm_path = self.project_location + '/odm_dem/dtm.tif'
        ortho_path = self.project_location + '/odm_orthophoto/odm_orthophoto.tif'

        # ortho transform higher precision than dem transform 
        with rio.open(ortho_path) as ortho:
            # affine is used to transform from pixel x,y to coorinate system and back
            self.affine = ortho.transform

            # 0,4 are locations of pixel size in affine according to
            #https://gis.stackexchange.com/questions/243639/how-to-take-cell-size-from-raster-using-python-or-gdal-or-rasterio
            self.x_pixel_len = self.affine[0]
            self.y_pixel_len = -self.affine[4]

        with rio.open(dsm_path) as dsm_dataset:
            with rio.open(dtm_path) as dtm_dataset:
                assert dsm_dataset.bounds == dtm_dataset.bounds

                self.bounds = dsm_dataset.bounds
                # read the dsm_dataset into np array form
                # use read(1) since shape is (1, x, y) read(1) causes output to be (x,y) removing need for a reshape
                self.dsm = dsm_dataset.read(1, masked=True)  # mask might be necessary, but messes with subtraction
                self.dtm = dtm_dataset.read(1, masked=True)

                # find the element by element difference of the models to detect object heights
                print('Creating canopy model', flush=True)
                self.canopy_model = self.dsm - self.dtm


    def find_volume(self):
        # check if volume has already been calculated
        print('Calculating volume of GeoTiff, may take a some time', flush=True)
        # ordering of bounds tuple is 0 left, 1 bottom, 2 right, 3 top
        width = self.bounds[2]- self.bounds[0]
        length = self.bounds[3] - self.bounds[1]

        print(self.canopy_model.shape) 
        width_pixels, length_pixels = self.canopy_model.shape
        sum_pixel_height = np.sum(self.canopy_model)
        # area of each individual pixel = total area / # of pixels
        area_of_pixel = self.y_pixel_len * self.x_pixel_len

        #print('num of good pixels =', num_good_values)
        print(f'{sum_pixel_height=}, {area_of_pixel=}')
        '''
        VOLUME = area_of_pixel * sum_pixel_height
        area_of_pixel = (metric_length*metric_height) / (num_length_pixel *num_width_pixel)
        '''
        self.volume = sum_pixel_height * area_of_pixel
        return self.volume


    # shows orthophoto with gcp plotted
    def show_orthophoto(self):
        files = os.listdir(self.project_location)
        if 'gcp_list.txt' not in files:
            print('no GCP file to compare with')
            return -1
        unique_GCP = [] 
        gcp_location = self.project_location + '/gcp_list.txt'
        with open(gcp_location, 'r') as gcp:
            Lines = gcp.readlines()
            # first line is identification string so remove
            utm_string = Lines.pop(0)
            for line in Lines:
                # split line on spaces
                splits = line.split()
                # first two items are the coordinates
                x,y  = splits[0], splits[1]
                if (x,y) not in unique_GCP:
                    # if x,y pair first of its kind then append to list, convert from string to float for indexing later
                    unique_GCP.append((float(x),float(y)))
        # unique GCP is a list of all unique GCP that should be in orthophoto


        orthophoto_path = self.project_location + '/odm_orthophoto/odm_orthophoto.tif'
        img = rio.open(orthophoto_path)

        x_val, y_val = [], []
        for gcp in unique_GCP:
            # index converts the coordinate to pixel value in the given picture
            row_pix, col_pix = self.index_to_pixel(gcp[0], gcp[1])
            x_val.append(col_pix)
            y_val.append(row_pix)
       
        # convert rasterio img to np array
        arr = img.read()
        arr = arr[:3]
        # move color layer to the back
        # before change is 3,l,w needs to be l,w,3
        rgb_arr = np.transpose(arr, (1,2,0))
        pyplot.imshow(rgb_arr)
        # note pyplot inverts axis here so must feed it y,x instead of x,y
        pyplot.plot(x_val, y_val, '.', color='red')
        #pyplot.savefig(self.locations['project_location']+'/python_output/orthophoto.jpg')
        pyplot.show()

if __name__ == '__main__':
    loc = 'C:/Users/Hypnotic/Desktop/ODM/Unit_020_D'
    odm_pre = ODMEval(loc)
    x,y = odm_pre.index_to_coordinate(3000,3000)
    mini_area = odm_pre.mini_area(x,y)

